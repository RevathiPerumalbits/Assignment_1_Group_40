name: Iris MLOps Pipeline

on:
  push:
    branches:
      - main

jobs:
  mlops-pipeline:
    runs-on: ubuntu-latest

    steps:
    # Checkout the repository
    - name: Checkout code
      uses: actions/checkout@v4

    # Set up Python environment
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    # Install dependencies
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    # Load data
    - name: Load data
      run: python src/data_loader.py

    # Preprocess data
    - name: Preprocess data
      run: python src/data_preparation.py

    # Train models
    - name: Train models
      env:
        MLFLOW_TRACKING_URI: sqlite:///mlruns.db
      run: |
        echo "MLflow tracking URI: $MLFLOW_TRACKING_URI"
        mlflow ui --port 5000 &
        sleep 5  # Wait for MLflow server to start
        python src/model_train.py
        cp -r mlruns /tmp/mlruns

    # Evaluate and register models
    - name: Evaluate and register models
      env:
        MLFLOW_TRACKING_URI: sqlite:///mlruns.db
      run: |
        echo "MLflow tracking URI: $MLFLOW_TRACKING_URI"
        cp -r /tmp/mlruns mlruns
        python src/model_evaluate.py

    # Build Docker image
    - name: Build Docker image
      run: |
        cp -r /tmp/mlruns .  # Restore MLflow artifacts for Docker build
        docker build -t iris-mlops-api .

    # Run Docker container
    - name: Run Docker container
      run: docker run -d -p 8000:8000 iris-mlops-api

    # Test API and log prediction
    - name: Test API and log prediction
      run: |
        sleep 5  # Wait for container to start
        curl -X POST "http://localhost:8000/predict" -H "Content-Type: application/json" -d '{"features": [5.1, 3.5, 1.4, 0.2]}' > prediction.json
        python -c "import json; import pandas as pd; import os; from datetime import datetime; data = json.load(open('prediction.json')); log_entry = {'timestamp': datetime.now().isoformat(), 'features': [5.1, 3.5, 1.4, 0.2], 'prediction': data['prediction']}; log_df = pd.DataFrame([log_entry]); os.makedirs('logs', exist_ok=True); log_df.to_csv('logs/predictions.csv', index=False)"

    # Upload prediction logs as artifact
    - name: Upload prediction logs
      uses: actions/upload-artifact@v4
      with:
        name: prediction-logs
        path: logs/predictions.csv
        if-no-files-found: warn
        include-hidden-files: false

    # Upload saved models as artifact
    - name: Upload saved models
      uses: actions/upload-artifact@v4
      with:
        name: saved-models
        path: saved_models/
        if-no-files-found: warn
        include-hidden-files: false

    # Upload MLflow artifacts
    - name: Upload MLflow artifacts
      uses: actions/upload-artifact@v4
      with:
        name: mlflow-artifacts
        path: mlruns/
        if-no-files-found: warn
        include-hidden-files: false